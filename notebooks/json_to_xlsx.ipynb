{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e02b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2ba73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 27 records into DataFrame.\n",
      "✅ Saved 27 records in results_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"/Users/delmedigo/Dev/langtest/langscrape/data/jsons\"\n",
    "\n",
    "mapping_dict = {\n",
    "    \"Number\": \"meta_data.id\",\n",
    "    \"Link\": \"meta_data.url\",\n",
    "    \"Title\": \"summary.title\",\n",
    "    \"Description*\": \"summary.summary\",\n",
    "    \"Published Date\": \"summary.publication_date\",\n",
    "    \"Event date from\": \"summary.event_start_date\",\n",
    "    \"Event date to\": \"summary.event_end_date\",\n",
    "    \"Platform\": \"summary.platform\",\n",
    "    \"Author\": \"summary.author\",\n",
    "    \"Source\": None,\n",
    "    \"Reference\": None,\n",
    "    \"Language\": \"summary.language\",\n",
    "    \"Location\": \"summary.location_tags\",\n",
    "    \"Type\": \"summary.type\",\n",
    "    \"Media\": \"summary.media\",\n",
    "    \"Theme (tag)\": \"summary.theme_tags\",\n",
    "    \"Places & Organizations (tag)\": \"summary.countries_and_organizations_tags\",\n",
    "    \"Locations (tag)\": \"summary.location_tags\",\n",
    "    \"Figures (tag)\": \"summary.figures_tags\",\n",
    "}\n",
    "\n",
    "def get_value(obj, path):\n",
    "    \"\"\"Resolve dotted paths like 'a.b[0]' safely.\"\"\"\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    parts = path.replace(\"]\", \"\").split(\".\")\n",
    "    current = obj\n",
    "    try:\n",
    "        for part in parts:\n",
    "            if \"[\" in part:\n",
    "                key, idx = part.split(\"[\")\n",
    "                current = current.get(key, [])[int(idx)]\n",
    "            else:\n",
    "                current = current.get(part, \"\")\n",
    "        if isinstance(current, list):\n",
    "            return \", \".join(map(str, current))\n",
    "        return current\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "rows = []\n",
    "files = [\n",
    "    f for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\") and f != \"links.csv\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        row = {}\n",
    "        for col, path_expr in mapping_dict.items():\n",
    "            row[col] = get_value(data, path_expr) if path_expr else \"\"\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {file}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"✅ Loaded {len(df)} records into DataFrame.\")\n",
    "df.to_excel(os.path.join(DATA_DIR, \"results_table.xlsx\"), index=False)\n",
    "print(f\"✅ Saved {len(df)} records in results_table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to load logging.json: 'meta_data'\n"
     ]
    }
   ],
   "source": [
    "extractor_inputs, extractor_outputs, summarizer_inputs, summarizer_outputs = [], [], [], []\n",
    "total_tokens = []\n",
    "for file in files:\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        extractor_inputs.append(data[\"meta_data\"]['token_usage'][\"extractor\"][\"input_tokens\"])\n",
    "        extractor_outputs.append(data[\"meta_data\"]['token_usage'][\"extractor\"][\"output_tokens\"])\n",
    "        summarizer_inputs.append(data[\"meta_data\"]['token_usage'][\"summarizer\"][\"input_tokens\"])\n",
    "        summarizer_outputs.append(data[\"meta_data\"]['token_usage'][\"summarizer\"][\"output_tokens\"])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f3add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy\n",
    "def get_metrics(l):\n",
    "    l = [e for e in l if e != 0]\n",
    "    if isinstance(l, list):\n",
    "        return mean(l), max(l), min(l)\n",
    "    elif isinstance(l, numpy.int64):\n",
    "        return mean(l).item(), max(l).item(), min(l).item()\n",
    "    else:\n",
    "        return mean(l).item(), max(l).item(), min(l).item()\n",
    "\n",
    "a, b, c = get_metrics(numpy.array(extractor_inputs) + numpy.array(extractor_outputs) + numpy.array(summarizer_inputs) + numpy.array(summarizer_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c152c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 32271 max: 54881 min: 10704\n"
     ]
    }
   ],
   "source": [
    "print(\"mean:\",a,\"max:\",b,\"min:\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper4k\n",
      "  Downloading newspaper4k-0.9.3.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow>=4.0.0 (from newspaper4k)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (6.0.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.3 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (4.14.2)\n",
      "Collecting feedparser>=6.0.0 (from newspaper4k)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: lxml>=4.2.0 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (6.0.2)\n",
      "Collecting nltk>=3.6.6 (from newspaper4k)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.25 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (2.3.3)\n",
      "Requirement already satisfied: pandas>=2.1.0 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from newspaper4k) (2.32.5)\n",
      "Collecting tldextract>=2.0.1 (from newspaper4k)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from beautifulsoup4>=4.9.3->newspaper4k) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from beautifulsoup4>=4.9.3->newspaper4k) (4.15.0)\n",
      "Collecting sgmllib3k (from feedparser>=6.0.0->newspaper4k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting click (from nltk>=3.6.6->newspaper4k)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk>=3.6.6->newspaper4k)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from nltk>=3.6.6->newspaper4k) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from nltk>=3.6.6->newspaper4k) (4.67.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from pandas>=2.1.0->newspaper4k) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from pandas>=2.1.0->newspaper4k) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from python-dateutil>=2.6.1->newspaper4k) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from requests>=2.26.0->newspaper4k) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from requests>=2.26.0->newspaper4k) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from requests>=2.26.0->newspaper4k) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from requests>=2.26.0->newspaper4k) (2025.10.5)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper4k)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from tldextract>=2.0.1->newspaper4k) (3.20.0)\n",
      "Downloading newspaper4k-0.9.3.1-py3-none-any.whl (296 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=1f926b3cd4a549f5c06c058ce445ccaa45f1fa628dcd1d9b4fbb44415a06c6a0\n",
      "  Stored in directory: /Users/delmedigo/Library/Caches/pip/wheels/e3/43/83/0f6e317d0698ac38ee6a5b6e214019c167057916a11bad91ab\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, Pillow, joblib, feedparser, click, requests-file, nltk, tldextract, newspaper4k\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [newspaper4k]\u001b[0m [nltk]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Pillow-12.0.0 click-8.3.0 feedparser-6.0.12 joblib-1.5.2 newspaper4k-0.9.3.1 nltk-3.9.2 requests-file-3.0.1 sgmllib3k-1.0.0 tldextract-5.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml_html_clean\n",
      "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: lxml in /Users/delmedigo/Dev/langtest/langscrape/.env/lib/python3.14/site-packages (from lxml_html_clean) (6.0.2)\n",
      "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e90715",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m newspaper --url=\"https://edition.cnn.com/2023/11/17/success/job-seekers-use-ai/index.html\" --language=en --output-format=json --output-file=article.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/delmedigo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce51f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "\n",
    "article = newspaper.article('https://www.haaretz.co.il/magazine/2025-10-23/ty-article-magazine/.highlight/0000019a-0a73-dfc6-a3bf-fb77ff1e0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7126d334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c19eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
