{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e02b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SCHEME = {\n",
    "    \"title_in_english\": \"The title of the content in english\",\n",
    "    \"title_in_hebrew\": \"The title of the content in hebrew\",\n",
    "    \"author_in_english\": \"The content's author name (string, empty if unknown) in english\",\n",
    "    \"author_in_hebrew\": \"The content's author name (string, empty if unknown) in hebrew\",\n",
    "    \"publication_date\": \"YYYY-MM-DD\",\n",
    "    \"language\": \"The primary language of the content\",\n",
    "    \"type\": \"One of the content types listed above\",\n",
    "    \"media\": \"One or more of the media types listed above\",\n",
    "    \"platform\": \"The website or platform where the content is published\",\n",
    "    \"source\": \"for example, if a media post is reposting, or showing a Guardian's interview - the source = 'Guardian'\",\n",
    "    \"reference\": \"a link to the primary document or official source cited (string, empty if none)\",\n",
    "    \"summary_in_enlgish\": \"One clear, informative sentence summarizing the main content, in english\",\n",
    "    \"summary_in_hebrew\": \"One clear, informative sentence summarizing the main content, in hebrew\",\n",
    "    \"event_start_date\": \"YYYY-MM-DD\",\n",
    "    \"event_end_date\": \"YYYY-MM-DD\",\n",
    "    \"theme_tags\": [\"relevant\", \"theme\", \"tags\"],\n",
    "    \"countries_and_organizations_tags\": [\"relevant\", \"countries_and_organizations\", \"tags\"],\n",
    "    \"free_location_tags\": [\"relevant\", \"specific\", \"location\", \"tags\", \"not nessearily from the list of tags allowed.\"],\n",
    "    \"location_tags\": [\"relevant\", \"location\", \"tags\"],\n",
    "    \"figures_tags\": [\"relevant\", \"figures\", \"tags\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2ba73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 29 records into DataFrame.\n",
      "✅ Saved 29 records in results_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"/Users/delmedigo/Dev/langtest/langscrape/data/experiment_08_10_2025 copy/jsons\"\n",
    "\n",
    "mapping_dict = {\n",
    "    \"Number\": \"meta_data.id\",\n",
    "    \"Link\": \"meta_data.url\",\n",
    "    \"English Title\": \"summary.title_in_english\",\n",
    "    \"Hebrew Title\": \"summary.title_in_hebrew\",\n",
    "    \"English Description\": [\"summary.summary_in_enlgish\", \"summary.summary_in_english\"],\n",
    "    \"Hebrew Description\": \"summary.summary_in_hebrew\",\n",
    "    \"Published Date\": \"summary.publication_date\",\n",
    "    \"Event date from\": \"summary.event_start_date\",\n",
    "    \"Event date to\": \"summary.event_end_date\",\n",
    "    \"Platform\": \"summary.platform\",\n",
    "    \"Author (English)\": \"summary.author_in_english\",\n",
    "    \"Author (Hebrew)\": \"summary.author_in_hebrew\",\n",
    "    \"Source\": \"summary.source\",\n",
    "    \"Reference\": \"summary.platform\",\n",
    "    \"Language\": \"summary.language\",\n",
    "    \"Location\": \"summary.free_location_tags\",\n",
    "    \"Type\": \"summary.type\",\n",
    "    \"Media\": \"summary.media\",\n",
    "    \"Theme\": \"summary.theme_tags\",\n",
    "    \"Countries & Organizations\": \"summary.countries_and_organizations_tags\",\n",
    "    \"Location (tag)\": \"summary.location_tags\",\n",
    "    \"Figures\": \"summary.figures_tags\",\n",
    "}\n",
    "\n",
    "def get_value(obj, path):\n",
    "    \"\"\"Resolve dotted paths like 'a.b[0]' safely.\"\"\"\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    parts = path.replace(\"]\", \"\").split(\".\")\n",
    "    current = obj\n",
    "    try:\n",
    "        for part in parts:\n",
    "            if \"[\" in part:\n",
    "                key, idx = part.split(\"[\")\n",
    "                current = current.get(key, [])[int(idx)]\n",
    "            else:\n",
    "                current = current.get(part, \"\")\n",
    "        if isinstance(current, list):\n",
    "            return \", \".join(map(str, current))\n",
    "        return current\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "rows = []\n",
    "files = [\n",
    "    f for f in os.listdir(DATA_DIR)\n",
    "    if f.endswith(\".json\") and f != \"links.csv\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        row = {}\n",
    "        for col, path_expr in mapping_dict.items():\n",
    "            if isinstance(path_expr, list):\n",
    "                for p in path_expr:\n",
    "                    value = get_value(data, p) if p else \"\"\n",
    "                    if value != \"\":\n",
    "                        row[col] = value\n",
    "            else:\n",
    "                row[col] = get_value(data, path_expr) if path_expr else \"\"\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {file}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"✅ Loaded {len(df)} records into DataFrame.\")\n",
    "df.to_excel(os.path.join(DATA_DIR, \"results_table.xlsx\"), index=False)\n",
    "print(f\"✅ Saved {len(df)} records in results_table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f665550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to load logging.json: 'meta_data'\n"
     ]
    }
   ],
   "source": [
    "extractor_inputs, extractor_outputs, summarizer_inputs, summarizer_outputs = [], [], [], []\n",
    "total_tokens = []\n",
    "for file in files:\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        extractor_inputs.append(data[\"meta_data\"]['token_usage'][\"extractor\"][\"input_tokens\"])\n",
    "        extractor_outputs.append(data[\"meta_data\"]['token_usage'][\"extractor\"][\"output_tokens\"])\n",
    "        summarizer_inputs.append(data[\"meta_data\"]['token_usage'][\"summarizer\"][\"input_tokens\"])\n",
    "        summarizer_outputs.append(data[\"meta_data\"]['token_usage'][\"summarizer\"][\"output_tokens\"])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy\n",
    "def get_metrics(l):\n",
    "    l = [e for e in l if e != 0]\n",
    "    if isinstance(l, list):\n",
    "        return mean(l), max(l), min(l)\n",
    "    elif isinstance(l, numpy.int64):\n",
    "        return mean(l).item(), max(l).item(), min(l).item()\n",
    "    else:\n",
    "        return mean(l).item(), max(l).item(), min(l).item()\n",
    "\n",
    "a, b, c = get_metrics(numpy.array(extractor_inputs) + numpy.array(extractor_outputs) + numpy.array(summarizer_inputs) + numpy.array(summarizer_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c152c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean:\",a,\"max:\",b,\"min:\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f60e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e90715",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m newspaper --url=\"https://edition.cnn.com/2023/11/17/success/job-seekers-use-ai/index.html\" --language=en --output-format=json --output-file=article.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce51f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "\n",
    "article = newspaper.article('https://www.haaretz.co.il/magazine/2025-10-23/ty-article-magazine/.highlight/0000019a-0a73-dfc6-a3bf-fb77ff1e0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c19eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
