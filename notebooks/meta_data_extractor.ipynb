{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332584d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict, Optional\n",
    "import dateparser\n",
    "\n",
    "def _traditional_extract_metadata(html_content: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"Traditional metadata extraction method as fallback\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    metadata = {\n",
    "        'author': None,\n",
    "        'publication_date': None,\n",
    "        'title': None,\n",
    "    }\n",
    "    \n",
    "    # Multiple patterns for author\n",
    "    try:\n",
    "        author = None\n",
    "        # First try meta tags\n",
    "        author_patterns = [\n",
    "            {'name': 'author'},\n",
    "            {'property': 'author'},\n",
    "            {'property': 'article:author'},\n",
    "            {'name': 'byl'},\n",
    "            {'name': 'twitter:creator'},\n",
    "        ]\n",
    "        \n",
    "        for pattern in author_patterns:\n",
    "            meta_tag = soup.find('meta', pattern)\n",
    "            if meta_tag and meta_tag.get('content'):\n",
    "                author = meta_tag['content']\n",
    "                break\n",
    "        \n",
    "        # If no meta tag found, try looking for common author HTML patterns\n",
    "        if not author:\n",
    "            # Look for authors div with nested spans\n",
    "            authors_div = soup.find('div', class_=['authors', 'contributor', 'contributors'])\n",
    "            if authors_div:\n",
    "                # Try to find nested spans or links\n",
    "                author_elements = authors_div.find_all(['span', 'a'])\n",
    "                if author_elements:\n",
    "                    authors = [elem.get_text().strip() for elem in author_elements if elem.get_text().strip()]\n",
    "                    author = ', '.join(authors)\n",
    "            \n",
    "            # If still no author, try other common patterns\n",
    "            if not author:\n",
    "                author_elements = soup.select('a[rel=\"author\"], .author, .byline, .c-author, [itemprop=\"author\"], .contributor, .contributors')\n",
    "                if author_elements:\n",
    "                    author = author_elements[0].get_text().strip()\n",
    "                \n",
    "        metadata['author'] = author\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting author: {str(e)}\")\n",
    "        pass\n",
    "    \n",
    "    # Publication date extraction with standardized format\n",
    "    try:\n",
    "        date = None\n",
    "        date_patterns = [\n",
    "            {'name': 'publication_date'},\n",
    "            {'property': 'article:published_time'},\n",
    "            {'property': 'article:published'},\n",
    "            {'name': 'date'},\n",
    "            {'itemprop': 'datePublished'},\n",
    "            {'name': 'publishedDate'},\n",
    "        ]\n",
    "        \n",
    "        for pattern in date_patterns:\n",
    "            meta_tag = soup.find('meta', pattern)\n",
    "            if meta_tag and meta_tag.get('content'):\n",
    "                date = meta_tag['content']\n",
    "                break\n",
    "                \n",
    "        # If no meta tag found, try looking for time elements\n",
    "        if not date:\n",
    "            time_elements = soup.find_all('time')\n",
    "            for time_elem in time_elements:\n",
    "                if time_elem.get('datetime'):\n",
    "                    date = time_elem['datetime']\n",
    "                    break\n",
    "                elif time_elem.get('data-timestamp'):\n",
    "                    date = time_elem['data-timestamp']\n",
    "                    break\n",
    "                \n",
    "        # Standardize date format if a date was found\n",
    "        if date:\n",
    "            parsed_date = dateparser.parse(date)\n",
    "            if parsed_date:\n",
    "                metadata['publication_date'] = parsed_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Title extraction (keeping existing implementation)\n",
    "    try:\n",
    "        metadata['title'] = soup.find('title').text.strip()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c75ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional, List\n",
    "import json\n",
    "import re\n",
    "\n",
    "def _traditional_extract_article_body(html_content: str) -> Optional[str]:\n",
    "    \"\"\"Traditional article-body extraction as a fallback.\n",
    "    Tries common containers, scores candidates, removes boilerplate, and returns cleaned text.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Remove obvious noise upfront\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"svg\", \"canvas\", \"form\"]):\n",
    "        tag.decompose()\n",
    "    # Remove common non-content blocks (ads, nav, etc.)\n",
    "    for sel in [\n",
    "        \"[role='navigation']\",\n",
    "        \"nav\",\n",
    "        \"header\",\n",
    "        \"footer\",\n",
    "        \"aside\",\n",
    "        \".ads, .ad, .advert, [id*='ad-'], [class*='ad-']\",\n",
    "        \".subscribe, .paywall, .newsletter\",\n",
    "        \".share, .social, .comments, #comments\",\n",
    "        \".breadcrumbs, .tags, .related, .recommendations\",\n",
    "        \"figure, .figure, .media, .video, .photo, .gallery\",\n",
    "    ]:\n",
    "        for el in soup.select(sel):\n",
    "            el.decompose()\n",
    "\n",
    "    # 1) Try JSON-LD articleBody if available (some sites embed full text here)\n",
    "    try:\n",
    "        for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "            data = json.loads(script.string or \"\")\n",
    "            # Normalize to list for easy iteration\n",
    "            items: List[dict] = data if isinstance(data, list) else [data]\n",
    "            for item in items:\n",
    "                if isinstance(item, dict):\n",
    "                    # Article-like types\n",
    "                    t = item.get(\"@type\") or item.get(\"type\")\n",
    "                    if isinstance(t, list):\n",
    "                        is_article = any(x.lower().endswith(\"article\") for x in map(str, t))\n",
    "                    else:\n",
    "                        is_article = str(t).lower().endswith(\"article\") if t else False\n",
    "                    if is_article and item.get(\"articleBody\"):\n",
    "                        text = str(item.get(\"articleBody\")).strip()\n",
    "                        if text:\n",
    "                            # Normalize whitespace\n",
    "                            text = re.sub(r\"\\s+\\n\", \"\\n\", text)\n",
    "                            text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "                            return text or None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Candidate selectors for typical CMS structures\n",
    "    selectors = [\n",
    "        \"main article\",\n",
    "        \"article\",\n",
    "        \"[itemprop='articleBody']\",\n",
    "        \"section[itemprop='articleBody']\",\n",
    "        \"div[itemprop='articleBody']\",\n",
    "        \"div[data-component='article-body']\",\n",
    "        \"section[data-component='article-body']\",\n",
    "        \".article-body, .articleBody, .article__body, .c-article-body, .l-articleBody\",\n",
    "        \".content__article-body, .content-article__body\",\n",
    "        \".entry-content, .post-content, .post__content, .td-post-content\",\n",
    "        \".story-body, #story-body, #article-body\",\n",
    "        \".article-content, .article__content, .article--content, .articleText, .article-text\",\n",
    "        \".field-name-body, .content-body, .single-content\",\n",
    "        \".rich-text, .wysiwyg-content\",\n",
    "        \"main .content, main .container, main .post, main .entry\",\n",
    "    ]\n",
    "\n",
    "    def score_node(node) -> int:\n",
    "        \"\"\"Heuristic score: prefer many <p>, long text; penalize link-heavy blocks.\"\"\"\n",
    "        if not node:\n",
    "            return -1\n",
    "        # Gather paragraph text\n",
    "        ps = node.find_all(\"p\")\n",
    "        p_text = \"\\n\".join(p.get_text(separator=\" \", strip=True) for p in ps)\n",
    "        p_len = len(p_text)\n",
    "\n",
    "        # Link density penalty\n",
    "        links = node.find_all(\"a\")\n",
    "        link_text_len = sum(len(a.get_text() or \"\") for a in links)\n",
    "        link_density = (link_text_len / p_len) if p_len > 0 else 1.0\n",
    "\n",
    "        # Headings can be informative; slight boost\n",
    "        headings = node.find_all([\"h2\", \"h3\"])\n",
    "        h_count = len(headings)\n",
    "\n",
    "        # Score components\n",
    "        score = (\n",
    "            (len(ps) * 30) +           # more paragraphs is good\n",
    "            (p_len // 50) +            # longer text is good\n",
    "            (h_count * 5)              # some headings help\n",
    "        )\n",
    "        # Penalize high link density\n",
    "        score -= int(link_density * 20)\n",
    "\n",
    "        return score\n",
    "\n",
    "    # 3) Collect candidates and score\n",
    "    candidates = []\n",
    "    for sel in selectors:\n",
    "        for node in soup.select(sel):\n",
    "            candidates.append((score_node(node), node))\n",
    "\n",
    "    # 4) If nothing matched, broaden: look for the largest <main> or central column\n",
    "    if not candidates:\n",
    "        broad_selectors = [\"main\", \"#main\", \".main\", \".content\", \"#content\", \".container\", \".article\"]\n",
    "        for sel in broad_selectors:\n",
    "            for node in soup.select(sel):\n",
    "                candidates.append((score_node(node), node))\n",
    "\n",
    "    # 5) Choose best candidate and build text\n",
    "    best_text = \"\"\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "        _, best = candidates[0]\n",
    "\n",
    "        # Inside the best node, prefer paragraphs and simple headings\n",
    "        parts: List[str] = []\n",
    "        for el in best.find_all([\"h2\", \"h3\", \"p\", \"li\"]):\n",
    "            # Skip very short crumbs / nav-like items\n",
    "            t = el.get_text(separator=\" \", strip=True)\n",
    "            if not t:\n",
    "                continue\n",
    "            if len(t) < 3:\n",
    "                continue\n",
    "            parts.append(t)\n",
    "\n",
    "        best_text = \"\\n\\n\".join(parts).strip()\n",
    "\n",
    "    # 6) Ultimate fallback: all <p> in document (but try to keep it sane)\n",
    "    if not best_text:\n",
    "        ps = [p.get_text(separator=\" \", strip=True) for p in soup.find_all(\"p\")]\n",
    "        ps = [t for t in ps if len(t) > 30]  # filter out tiny snippets\n",
    "        best_text = \"\\n\\n\".join(ps).strip()\n",
    "\n",
    "    # 7) Clean & normalize whitespace\n",
    "    if best_text:\n",
    "        best_text = re.sub(r\"[ \\t]+\\n\", \"\\n\", best_text)\n",
    "        best_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", best_text)\n",
    "        best_text = re.sub(r\"[ \\t]{2,}\", \" \", best_text).strip()\n",
    "\n",
    "    return best_text or None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19924de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['איתי יעקב'],\n",
       " '2025-10-24',\n",
       " 'בלילה שבין מותם הטרגי של אמה, מיכל זקס, בעלת עסק לבניית ציפורניים, ואחיה, רב טוראי איתן זקס, מפגיעת טיל ישירה בביתם שבבאר שבע בחודש יוני, לבין טקס הלוויה, ישבה אליענה זקס והכינה שתי רשימות. האחת מורכבת מ-20 דברים שהיא רוצה להגשים עבורם, כמו לטייל בכל המדינות שאחיה בן ה-18 חלם ולא הספיק לראות בעיניו; השנייה היא 20 הרגלים אישיים, עשרה לכל אחד, שהיא רוצה לאמץ כדי לברוא אליענה חדשה. \"אני חושבת שהם היו אנשים הרבה יותר טובים ממני, אנשים של נתינה\", היא אומרת בריאיון מיוחד ל-מגזין סופ\"ש של ynet ארבעה חודשים לאחר אותה טרגדיה.\\n\\nמה היית רוצה שאנשים ידעו וילמדו מהם? \"הייתי רוצה שחבר\\'ה בגילו של אחי ילמדו ממנו אהבת הארץ. למרות הכול. הוא אהב את המדינה ואהב אנשים. הוא היה אוזן קשבת לכל אדם שהוא פגש והייתה לו יכולת פנומנלית להתחבר לאנשים מכל גיל ומעמד. מאז שהוא נפטר, עשרות החברים שלו לא עזבו את אבא שלי, מה שמראה איזה בן אדם של אנשים הוא היה. גם אמא שלי הייתה אדם מאוד חברותי ומלאה בנתינה, שהקדישה חלק גדול מחייה לאחרים – בין אם זה לאסוף סלי מזון לחיילים ולהסיע אותם לבסיסים, ולעזור לחולי סרטן אחרי שהיא בעצמה ניצחה אותו. למדתי ממנה לחיות את הרגע\".\\n\\nמה הדבר הראשון ברשימה שכתבת? \"לעשות את אמא שלי גאה\", היא מחייכת בביישנות. \"חודשיים לפני מותה, היא השאירה לי צוואה. היא שלחה לי תמונה עם ציטוט (ככל הנראה המיוחס לפילוסופית והסופרת סימון דה בובואר, א\"י), שגם אם היא לא תהיה לידי יותר, שאזכור שאני חזקה, חכמה והכי טובה. אני זוכרת שכתבתי לה: \\'מה קורה לך? מה ההודעה ההזויה הזאת?\\' והיא אמרה: \\'שיהיה לך\\'. כל חיי הייתי אדם מאוד מרצה: תלמידה מצטיינת, מדגמנת למותגים הכי טובים, עובדת בחברת היי-טק. אף פעם לא היה מקום למה אליענה רוצה וחושבת, ואמרתי לעצמי שזהו, הדבר האחרון שאמא שלי אמרה לי הוא שמתסכל אותה שאני מתנהגת כדי לרצות אותם. עכשיו אני מקיימת את צוואתה\".\\n\\n\"אבא שלי גמגם ברוסית ואמר לי \\'אליענה, הם מתים\\'\"\\n\\nבבוקר ה-24 ביוני, אזרחי ישראל שאפו להתעורר אל הפסקת האש בין ישראל לאיראן. מבצע עם כלביא שנפתח תריסר ימים קודם לכן בתקיפת ישראל את מתקני הגרעין של איראן גבה הרס רב, 31 הרוגים, ופצועים רבים בגוף ובנפש. שעתיים לפני הפסקת האש, נשלח מטח בלתי פוסק של 22 טילים לעבר באר שבע. פגיעה ישירה אחת בקומפלקס מגורים בעיר גבתה ארבע נפשות: מיכל זקס (50) והבן איתן (18); חברתו נועה בוגוסלבסקי (18) מערד, ששהתה אצלו באותו יום; והשכנה מלמעלה, נעמי שאנן (73).\\n\\nבשעה חמש בבוקר התעוררה זקס בביתה שבתל אביב עם בן זוגה ושני הכלבים מאזעקה. הם רצו למקלט שבבניין וכשחזרו, החל בן זוגה לקרוא הודעות בטלגרם על הפגיעות בבאר שבע. \"הסתכלתי על התמונה בחצי עין ואמרתי לו שזאת השכונה של ההורים שלי, אבל זה לא הבית שלהם, וחזרנו לישון\", היא מספרת בריאיון גדול ראשון מאז הטרגדיה שפקדה אותה לפני ארבעה חודשים. זקס מגוללת ברגישות ובגרפיות את סיפור אותו בוקר שחור וחלקים מהכתבה עלולים להיות קשים לקריאה. זהו סיפורה.\\n\\nשטף האזעקות שלא פסק באותו בוקר העלה והוריד אותם פעמים נוספות למקלט. במקביל התמלאו הרשתות החברתיות בתמונות שהגיעו מבאר שבע, בעוד מנגנון ההדחקה שלה עבד שעות נוספות. \"הסתכלתי על התמונות ואמרתי לבן הזוג שלי: \\'אלו שני בניינים פינתיים שמחוברים עם ארבע חזיתות שונות\\'. לא ממש הבנתי אם זה הבניין שלהם או הבניין השני\".\\n\\nאבל בכל זאת, היא החליטה להרים טלפון. האנשים שהיו הכי זמינים עבורה לא ענו בצד השני. עשר דקות לאחר מכן היא קיבלה רמז ויזואלי למה שקרה. \"פתחנו טלוויזיה ובחדשות הופיע צילום מרחפן של בניין מפורק, ואני מסתכלת על המסך ורואה נדנדה מקש שהייתה במרפסת של ההורים שלי. המרפסת איננה, רק הנדנדה נותרה. שם הבנתי שזה הבית של ההורים שלי.\\n\\n\"התקשרתי פעם אחר פעם והם לא ענו, ובמקביל היו עוד ועוד אזעקות. רצנו למקלט שלא הייתה בו קליטה, ובאיזשהו שלב אמרתי לרוני בן זוגי: \\'נוסעים לשם עכשיו!\\' לקחנו את שני הכלבים וטסנו במהירות שיא מתל אביב לבאר שבע. וכל הזמן הזה אף אחד לא עונה לי בטלפון. לא ההורים שלי, לא אחי, לא החברה שלו נועה.\\n\\n\"תוך כדי הדרך לבאר שבע, באינסטגרם של ynet פורסם פוסט ובו תמונה של הבית של ההורים שלי. שיתפתי את זה בסטורי וכתבתי שם שאם מישהו ראה את מיכל ואיגור זקס, שייצור איתי קשר. במקביל דודה שלי התקשרה ואמרה שהיא ראתה את הבניין בחדשות והיא לא יודעת מה לעשות. התקשרנו לכל הגופים הרשמיים ולא קיבלנו תשובות, כי אסור היה להם לומר על מיקום הפגיעה. לא ידענו לאן להגיע.\\n\\n\"בכניסה לבאר שבע קיבלתי התראה בנייד מאתר חדשות על שלושה הרוגים – שתי נשים וגבר – בפגיעה בבאר שבע, ואני מסתכלת על בן הזוג שלי ברכב ואומרת לו: \\'זה הם. חד-משמעית\\'\".\\n\\nהם המשיכו ישירות לבית החולים סורוקה. בן הזוג נשאר בחוץ עם שני הכלבים בזמן שהיא רצה לטיפול נמרץ. בהתחלה אמרו לה שאין שם מישהו ממשפחת זקס, אבל אז עובד בדלפק צעק לה: הם פה!\\n\\n\"ירדה לי אבן מהלב\", היא מספרת, \"אנחנו משפחה של ארבע נפשות, אז הנחתי שזה שלושתם\".\\n\\nהיא הובלה לחדר עם וילון שמאחוריו פגשה את אביה, והבינה שהיא צריכה לגייס את כל הכוחות שלה להיות עכשיו המבוגר האחראי. \"הוא ישב שם בוכה, עם רעידות בגוף, נראה כאילו יצא מזירת פיגוע שותת דם עם רסיסים בגוף, גלדים ופציעת ראש. הבנתי שהוא יחיה. כששאלתי אותו איפה הם, הוא הסתכל עליי\", היא עוצרת ולוקחת נשימה. \"הוא גמגם ברוסית ואמר לי \\'אליענה, הם מתים\\'. לא הבנתי מה הוא אומר, לא הבנתי מי מת. הייתי בטוחה שאחי ואמא שלי שוכבים פצועים מאחורי וילון לידו.\\n\\n\"חיבקתי אותו והוא סיפר לי בדמעות שהוא נכנס לשירותים אחרי שהם יצאו מהממ\"ד ופתאום היה פיצוץ עז, וכשהוא יצא הוא מצא את שניהם מתים וגופותיהם מרוטשות. ואני לא מבינה מה הוא אומר לי. הוא סיפר לי איך הוא מצא כל אחד מהם ומתאר לי את זה ואני צורחת, מתחילה להשתגע שם, ותוך שנייה בן הזוג שלי מגיע ושואל מה קרה. ואני אומרת לו: \\'הם התפוצצו! והחברה של אחי עפה מההדף מחוץ לבניין!\"\\n\\nהטרגדיה של משפחת זקס היא תוצאה של פגיעת טיל ישירה בבניין. בני המשפחה הקפידו על ההנחיות ונשארו בממ\"ד, ומותם התרחש בין הנחיית פיקוד העורף לצאת מהמרחבים המוגנים לבין אזעקה נוספת שהגיעה באופן מיידי ולאחריה נשמע הפיצוץ.\\n\\n\"הממ\"ד התפוצץ והדלת של הממ\"ד קרסה על אמא שלי. אני לא יודעת אם הממ\"ד היה תקין או לא היה תקין, אבל המטבח נותר שלם עם סיר פתיתים ונקניקיות שאחי הכין ערב קודם לכן. אבא שלי היה בשירותים שבחזית המזרחית של הבניין, הצמודים לחדר העבודה של אמא שלי עם כלי החרס שנותרו שלמים ולחדרו של אחי שנשאר בסדר מופתי עם הגיטרות שלו. אם הם היו נשארים שם – הם היו בחיים. רק הממ\"ד והסלון שבמרכז הבית נחרבו. לא נותר מהם זכר\".\\n\\nיש בך כעס כלפי מישהו? \"אתה מנסה להבין מה מרגישים אחרי דבר כזה?\"\\n\\nאין דרך להבין באמת, אבל לאבל יש שלבים ואני תוהה באיזה שלב את נמצאת. \"מרגישים זעם מאוד גדול. לא על המדינה ולא על הפוליטיקאים, אלא על חוסר ההוגנות בחיים. על זה שאתה חסר אונים מול הגורל. הידיעה שבגיל כל כך צעיר איבדתי את המשפחה שלי הרתיחה אותי מכעס. אני רק בת 24 ושבועיים. רק חגגו לי יום הולדת! אחי היה במיונים להיות חובש קרבי, כי היה לו חשוב להציל את החברים בקרב. הוא תמיד אמר שטוב למות בעד ארצנו, ובסופו של דבר הוא נקטף אפילו לא מזה. אחי במקרה שוחרר ערב קודם הביתה, כי הבסיס שבו הוא שירת לא היה ממוגן, ובמקרה הוא והחברה שלו לא נסעו לבית של ההורים שלה בערד כי גם שם היו אזעקות. אני נותרתי בחיים אחרי שסירבתי להזמנה של ההורים שלי להגיע להיות אצלם.\\n\\n\"אני זוכרת שבבית החולים ליווה אותי קצין נפגעים ותהיתי אם נוכל לקיים את הלוויות בזמן, כי חששתי שאנשים ייפגעו מטילים והוא אמר \\'אליענה, לא יהיו אזעקות. יש הפסקת אש\\'. שעה קודם לכן, אמא שלי ואחי נהרגו מטיל ועכשיו אני צריכה לג\\'נגל בין טקס הקבורה של אמא שלי ואחי, היא אזרחית, הוא חייל (שניהם נקברו לבסוף יחד בחלקה הצבאית); לטפל באבא שלי ובעניינים לוגיסטיים שאף צעירה בת 24 לא צריכה להתעסק בהם. חצי מהמשפחה שלי נמחקה ואני עד עכשיו לא מעכלת את זה. מוות טרגי ומיותר, סטירה מצלצלת. אתה מרגיש שלוקחים לך חלק גדול מהגוף, ומתעורר בכל בוקר עם חור בלב\".\\n\\n\"כל השנים פחדתי להגיד שאני דוגמנית\"\\n\\nאליענה זקס נולדה ביוני 2001 בבית החולים סורוקה בבאר שבע. בגיל 18 עברה לתל אביב, שבה היא מתגוררת גם עכשיו. שנה קודם לכן החלה לדגמן, ועד היום הספיקה להצטלם למותגי אופנה רבים בישראל. גם אחיה איתן עשה באותה תקופה את צעדיו הראשונים כדוגמן. בימים אלו היא מופיעה בהפקת סתיו-חורף 2025-26 של פקטורי 54, לבושה במיטב הדגמים של בתי היוקרה הבינלאומיים הנמכרים בחנויות הבוטיק.\\n\\n\"זאת סגירת מעגל עבורי, כי זאת חנות שאמא שלי מאוד אהבה\", היא מספרת לאחר הצילומים שנערכו בסוף ספטמבר, ימים ספורים לפני ראש השנה. \"כל הקונספט של יום הצילום דיבר אליי, כי רצו להציג חוזק ועוצמה של אופנה. יש ימי צילום שאתה לא יוצא בהעצמה. שמחתי שבחרו בי, הגשמתי חלום ילדות\".\\n\\nזקס היא לא דוגמנית קלאסית, או לפחות לא עשתה את הדרך לעולם האופנה כמו דוגמניות אחרות שחלמו על כך מגיל צעיר. בתיכון השלימה תואר ראשון בכימיה ובכיתה י\"א החלה לדגמן בהשפעת האם, שהאמינה כי הדבר יחזק את הביטחון העצמי של אליענה.\\n\\n\"זה הגיע ממקום לא טוב שלי עם עצמי\", היא משתפת. \"הייתה לי שנאה עצמית גדולה בעקבות השינויים הפיזיולוגיים בגיל ההתבגרות. יום אחד אמא שלי ראתה פרסום רנדומלי בפייסבוק שמחפשים דוגמנית לצילומי בוטיק לשמלות כלה בתל אביב. היא פנתה למארגנים וזו הייתה טבילת האש הראשונה שלי. משם התגלגלתי לסוכנות יולי, שבה אני חתומה עד היום. בסוף יום הצילום הזה הרגשתי לראשונה בחיים שאני לא הבן אדם הכי מכוער בעולם\".\\n\\nהחברות בבית הספר לא שמחו בשבילה. \"באותו זמן עברתי חרם בבית הספר\", היא נזכרת. \"למדתי בכיתת מצטיינים ו-20 בנות החליטו בוקר אחד לא לדבר איתי. אני לא יודעת מה הסיבה המדויקת. בזמנו חשבתי שזה בגלל שאני לא מספיק יפה או לא מספיק רזה או לא מספיק טובה שהן יהיו חברות שלי\".\\n\\nעם תואר ראשון בכימיה, לא חשבת לפוצץ את הכיתה? \"האמת שלא\", היא אומרת בחיוך. \"אבל לפני כמה חודשים הצטלמתי לקמפיין גדול ותמונה שלי הופיעה בענק בגרנד קניון בעיר. זאת הייתה סגירת מעגל. אין באר-שבעי שלא ראה את זה\".\\n\\nכשאת מסתכלת אחורה, את מבינה שאולי הקשיים שעברת עם שנאה עצמית הם חלק טבעי מגיל ההתבגרות? \"אני עדיין עובדת על המקום של להסתכל על עצמי במראה בלי לרצות למות. ההורמונים בגיל ההתבגרות גורמים לרובנו להיות חסרי ביטחון מתוך איזו מחשבה שהמראה שלנו זה הדבר הכי חשוב. ככל שמתבגרים, מבינים שזה לא הדבר הכי חשוב. אני מבינה שהפנים שלי סימטריות ושכנראה אני לא נראית נורא, אבל אני לא נכנסת לחדר ומרגישה הבן אדם הכי יפה. אני משתדלת להאפיל על זה עם האופי והידע שלי, ולשים אותם בקדמת הבמה\".\\n\\nאת נשמעת נבוכה להודות שאת יפה. \"כל השנים פחדתי להגיד שאני דוגמנית. למרות שאנחנו בשנת 2025, פחדתי שיסתכלו עליי רק כפנים יפות. רציתי שידעו שיש בי משהו מעבר, מלבד המראה\".\\n\\nהשתמשת פעם ביופי שלך? \"כל חיי אני קורעת את התחת, סליחה על המילה, בשביל דברים שאני רוצה. ככה חינכו אותי, ככה גידלו אותי. אני לא מקשרת את ההצלחות שלי למראה שלי, כי כשאני נכנסת לחדר אני באותה נקודת התחלה כמו כל אדם אחר. אין לי יתרון\".\\n\\nאת חושבת שהצורך \"לקרוע את התחת\" זה כי את בת של מהגרים? \"שני ההורים שלי עבדו קשה ואמא שלי עשתה תואר במקביל לשלוש עבודות ושני ילדים קטנים. אבא שלי עבד קשה כל חייו ואני מעריכה את הערכים שהם הנחילו בי ובאחי. יש אנשים שנכנסים לחדר בזכות קשרים, כסף או שכבר הכינו את המקום עבורם, אבל אם בסופו של דבר יגלו שאתה ריק מתוכן ומעשייה – אתה תישאר באותו המקום. לחשוב שהכול מגיע לי בגלל הפרצוף היפה זה טיפשי בעיניי. בסופו של דבר, אתה צריך להוכיח את הערך האמיתי שלך\".\\n\\nזקס קיבלה פטור משירות צבאי לאחר שנולדה עם ספונדילוליזיס (פגם באחת מחוליות עמוד השדרה) תורשתי ופנתה לשירות לאומי בפרקליטות המדינה בתל אביב. \"רציתי לעשות משהו שווה ערך לתרומה למדינה במוסד ממשלתי\", היא אומרת ומסמנת את לימודי המשפטים כתחנה הבאה שלה. \"אני מאוד רוצה להשיג צדק לאנשים ואני מאמינה בחוקים. זה נשמע חנוני, אבל זה נותן לנו עמוד שדרה ומגדיר אותנו. אני רוצה ללכת לסנגוריה הציבורית, להילחם עבור אנשים שזקוקים לך ואין להם את הכסף\".\\n\\nלהיות עורכת דין מתוך מקום של צדק ולא מתוך פרנסה בלבד לאחר שעברת טרגדיה נוראית וחסרת צדק, זאת צוואה נוספת שכותבת את עצמה? \"זה גם מה שאני רשמתי לעצמי\".',\n",
       " 'אליענה זקס: \"חצי מהמשפחה שלי נמחקה. אני מתעוררת בכל בוקר עם חור בלב\"')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install newspaper4k lxml_html_clean\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
